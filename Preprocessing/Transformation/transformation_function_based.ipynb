{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddf303e",
      "metadata": {
        "id": "3ddf303e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats, fft\n",
        "from datetime import timedelta\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67ec0e10",
      "metadata": {},
      "source": [
        "**Labelling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49cb5b83",
      "metadata": {
        "id": "49cb5b83"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(file_path):\n",
        "    \"\"\"Load and preprocess the dataset.\"\"\"\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Clean column names\n",
        "    df.columns = df.columns.str.strip()\n",
        "    # Convert the 'date' column to datetime type\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    # Sort the data by cow and date\n",
        "    df = df.sort_values(by=['cow', 'date'])\n",
        "    return df\n",
        "\n",
        "def get_health_state_durations(df, health_state_column):\n",
        "    \"\"\"Calculate durations for a specific health state.\"\"\"\n",
        "    durations = []\n",
        "    # For each cow\n",
        "    for cow_id, group in df.groupby('cow'):\n",
        "        group = group.sort_values('date').reset_index(drop=True)\n",
        "        current_state = False\n",
        "        start_date = None\n",
        "        prev_date = None\n",
        "\n",
        "        for i, row in group.iterrows():\n",
        "            if row[health_state_column] == 1:\n",
        "                if not current_state:\n",
        "                    # Start new period\n",
        "                    current_state = True\n",
        "                    start_date = row['date']\n",
        "                elif prev_date is not None and (row['date'] - prev_date).days > 1:\n",
        "                    # Gap detected ‚Üí close previous period\n",
        "                    end_date = prev_date\n",
        "                    duration = (end_date - start_date).days + 1\n",
        "                    durations.append({\n",
        "                        'cow': cow_id,\n",
        "                        'health_state': health_state_column,\n",
        "                        'start_date': start_date,\n",
        "                        'end_date': end_date,\n",
        "                        'duration_days': duration\n",
        "                    })\n",
        "                    # Start new period\n",
        "                    start_date = row['date']\n",
        "            else:\n",
        "                if current_state:\n",
        "                    end_date = prev_date if prev_date is not None else row['date']\n",
        "                    duration = (end_date - start_date).days + 1\n",
        "                    durations.append({\n",
        "                        'cow': cow_id,\n",
        "                        'health_state': health_state_column,\n",
        "                        'start_date': start_date,\n",
        "                        'end_date': end_date,\n",
        "                        'duration_days': duration\n",
        "                    })\n",
        "                    current_state = False\n",
        "                    start_date = None\n",
        "            prev_date = row['date']\n",
        "\n",
        "        # Handle case where last rows are 1s\n",
        "        if current_state:\n",
        "            end_date = prev_date\n",
        "            duration = (end_date - start_date).days + 1\n",
        "            durations.append({\n",
        "                'cow': cow_id,\n",
        "                'health_state': health_state_column,\n",
        "                'start_date': start_date,\n",
        "                'end_date': end_date,\n",
        "                'duration_days': duration\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(durations)\n",
        "\n",
        "def compute_health_durations(df, health_states):\n",
        "    \"\"\"Compute and display health state durations.\"\"\"\n",
        "    state_durations = {}\n",
        "    durations_min_max = {}\n",
        "\n",
        "    # Compute durations for each health state\n",
        "    for state in health_states:\n",
        "        durations_df = get_health_state_durations(df, state)\n",
        "        state_durations[state] = durations_df\n",
        "\n",
        "        if not durations_df.empty:\n",
        "            min_duration = durations_df['duration_days'].min()\n",
        "            max_duration = durations_df['duration_days'].max()\n",
        "            durations_min_max[state] = {'min_days': min_duration, 'max_days': max_duration}\n",
        "        else:\n",
        "            durations_min_max[state] = {'min_days': None, 'max_days': None}\n",
        "\n",
        "    # Display results\n",
        "    for state, durations in durations_min_max.items():\n",
        "        min_days = durations['min_days']\n",
        "        max_days = durations['max_days']\n",
        "        if min_days is None or max_days is None:\n",
        "            print(f\"No data available for \\\"{state}\\\".\")\n",
        "        elif min_days == max_days:\n",
        "            print(f\"{state.capitalize()} lasts {min_days} day{'s' if min_days > 1 else ''}.\")\n",
        "        else:\n",
        "            print(f\"{state.capitalize()} lasts between {min_days} and {max_days} days.\")\n",
        "\n",
        "    return state_durations, durations_min_max\n",
        "\n",
        "# Load and preprocess data\n",
        "# df = load_and_preprocess_data(r\"filtered_dataset_more_than_18_obs.csv\")\n",
        "# Assuming health_states is defined (from dataset columns or predefined list)\n",
        "# health_states = ['oestrus', 'calving', 'lameness', 'mastitis', 'other_disease', 'acidosis', 'LPS', 'accidents', 'disturbance', 'mixing', 'management_changes']\n",
        "# state_durations, durations_min_max = compute_health_durations(df, health_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "137814a5",
      "metadata": {
        "id": "137814a5"
      },
      "outputs": [],
      "source": [
        "def label_and_align_data(df, health_states):\n",
        "    \"\"\"Label and align data with spread rules.\"\"\"\n",
        "    # Step 1: Identify event columns dynamically\n",
        "    non_event_cols = ['cow', 'date', 'hour', 'IN_ALLEYS', 'REST', 'EAT', 'ACTIVITY_LEVEL', 'OK']\n",
        "    event_cols = [col for col in df.columns if col not in non_event_cols]\n",
        "\n",
        "    # Step 2: Aggregate daily events\n",
        "    daily = df.groupby(['cow', 'date'])[event_cols].max().reset_index()\n",
        "    daily['date'] = pd.to_datetime(daily['date'])\n",
        "\n",
        "    # Step 3: Create full cow x day table\n",
        "    all_dates = pd.date_range(daily['date'].min() - timedelta(days=7), daily['date'].max() + timedelta(days=7))\n",
        "    cows = daily['cow'].unique()\n",
        "    full_daily = pd.MultiIndex.from_product([cows, all_dates], names=['cow', 'date']).to_frame(index=False)\n",
        "\n",
        "    # Merge and fill missing\n",
        "    full_daily = full_daily.merge(daily, on=['cow', 'date'], how='left')\n",
        "    full_daily[event_cols] = full_daily[event_cols].fillna(0)\n",
        "\n",
        "    # Add LABEL and default OK\n",
        "    full_daily['LABEL'] = 'control'\n",
        "    full_daily['OK'] = 1\n",
        "\n",
        "    # Step 4: Spread rules\n",
        "    spread_rules = {\n",
        "        'oestrus': {'before': 1, 'after': 1},\n",
        "        'calving': {'before': 2, 'after': 1},\n",
        "        'lameness': {'before': 2, 'after': 1},\n",
        "        'mastitis': {'before': 2, 'after': 1},\n",
        "        'acidosis': {'before': 2, 'after': 1},\n",
        "        'LPS': {'before': 2, 'after': 1},\n",
        "        'other_disease': {'before': 2, 'after': 1},\n",
        "        'accidents': {'before': 2, 'after': 1},\n",
        "        'disturbance': {'before': 0, 'after': 0},\n",
        "        'mixing': {'before': 0, 'after': 0},\n",
        "        'management_changes': {'before': 0, 'after': 0},\n",
        "    }\n",
        "\n",
        "    for cond in event_cols:\n",
        "        if cond not in spread_rules:\n",
        "            continue\n",
        "        sub = full_daily[full_daily[cond] == 1][['cow', 'date']].sort_values(['cow', 'date'])\n",
        "        for cow_id in sub['cow'].unique():\n",
        "            cow_days = sub[sub['cow'] == cow_id]['date'].sort_values()\n",
        "            episode = []\n",
        "            prev_day = None\n",
        "            for day in cow_days:\n",
        "                if prev_day is None or (day - prev_day).days > 1:\n",
        "                    if episode:\n",
        "                        min_day = min(episode)\n",
        "                        max_day = max(episode)\n",
        "                        spread = spread_rules[cond]\n",
        "                        spread_days = pd.date_range(min_day - timedelta(days=spread['before']), max_day + timedelta(days=spread['after']))\n",
        "                        mask = (full_daily['cow'] == cow_id) & (full_daily['date'].isin(spread_days))\n",
        "                        full_daily.loc[mask, cond] = 1\n",
        "                        full_daily.loc[mask & (full_daily['LABEL'] == 'control'), 'LABEL'] = cond\n",
        "                        full_daily.loc[mask, 'OK'] = 0\n",
        "                    episode = [day]\n",
        "                else:\n",
        "                    episode.append(day)\n",
        "                prev_day = day\n",
        "            if episode:\n",
        "                min_day = min(episode)\n",
        "                max_day = max(episode)\n",
        "                spread = spread_rules[cond]\n",
        "                spread_days = pd.date_range(min_day - timedelta(days=spread['before']), max_day + timedelta(days=spread['after']))\n",
        "                mask = (full_daily['cow'] == cow_id) & (full_daily['date'].isin(spread_days))\n",
        "                full_daily.loc[mask, cond] = 1\n",
        "                full_daily.loc[mask & (full_daily['LABEL'] == 'control'), 'LABEL'] = cond\n",
        "                full_daily.loc[mask, 'OK'] = 0\n",
        "\n",
        "    # Step 5: Prepare df before merging (drop event columns to avoid conflict)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.drop(columns=event_cols + ['OK'], errors='ignore')\n",
        "\n",
        "    # Merge cleanly\n",
        "    final = df.merge(full_daily[['cow', 'date', 'LABEL'] + event_cols + ['OK']], on=['cow', 'date'], how='left')\n",
        "\n",
        "    # Step 6: If a day was labeled with an event, update hourly events if missing\n",
        "    for cond in event_cols:\n",
        "        final.loc[(final['LABEL'] == cond) & (final[cond] == 0), cond] = 1\n",
        "\n",
        "    return final\n",
        "\n",
        "# Label and align data\n",
        "# final = label_and_align_data(df, health_states)\n",
        "# final.to_csv(r\"labelled&aligned_dataset.csv\", index=False)\n",
        "# final.head(24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9a68b3a",
      "metadata": {
        "id": "f9a68b3a"
      },
      "outputs": [],
      "source": [
        "def visual_check_labeling(df, cow_id=156):\n",
        "    \"\"\"Visual check of consecutive days labeling for a specific cow.\"\"\"\n",
        "    # Filter that cow\n",
        "    cow_data = df[df['cow'] == cow_id][['cow', 'date', 'hour', 'LABEL']]\n",
        "\n",
        "    # Group by date (daily view)\n",
        "    daily_view = cow_data.groupby(['cow', 'date'])['LABEL'].agg(lambda x: x.mode()[0]).reset_index()\n",
        "\n",
        "    # Display consecutive days\n",
        "    print(f\"Consecutive days labeling for Cow {cow_id}:\")\n",
        "    display(daily_view.sort_values('date'))\n",
        "\n",
        "# Visual check for a specific cow\n",
        "# visual_check_labeling(final, cow_id=156)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1580f7e",
      "metadata": {
        "id": "c1580f7e"
      },
      "source": [
        "**Investigating before imputation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dde1e568",
      "metadata": {
        "id": "dde1e568"
      },
      "outputs": [],
      "source": [
        "def investigate_before_imputation(file_path):\n",
        "    \"\"\"Investigate rows needing reassignment before imputation.\"\"\"\n",
        "    # Step 0: Load the dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Step 1: Define useful and unwanted classes\n",
        "    useful_classes = ['mastitis', 'lameness', 'oestrus', 'calving', 'other_disease', 'OK']\n",
        "    removed_classes = ['management_changes', 'mixing', 'disturbance', 'accidents', 'LPS', 'acidosis']\n",
        "\n",
        "    # Step 2: Tag samples based on unwanted classes\n",
        "    df['had_removed_class'] = df[removed_classes].max(axis=1)  # 1 if any unwanted class was active\n",
        "\n",
        "    # Step 3: After dropping unwanted classes, check if any useful class remains\n",
        "    df['has_useful_class'] = df[useful_classes].max(axis=1)  # 1 if any useful class active\n",
        "\n",
        "    # Step 4: Identify rows needing reassignment\n",
        "    rows_to_reassign = df[(df['had_removed_class'] == 1) & (df['has_useful_class'] == 0)]\n",
        "\n",
        "    # Step 5: Summary statistics\n",
        "    total_rows = len(df)\n",
        "    total_to_reassign = len(rows_to_reassign)\n",
        "    proportion = total_to_reassign / total_rows * 100\n",
        "\n",
        "    print(f\"Total rows in dataset: {total_rows}\")\n",
        "    print(f\"Rows needing reassignment: {total_to_reassign}\")\n",
        "    print(f\"Proportion needing reassignment: {proportion:.2f}%\")\n",
        "\n",
        "    return df, useful_classes, removed_classes\n",
        "\n",
        "# Investigate before imputation\n",
        "# df, useful_classes, removed_classes = investigate_before_imputation(r\"labelled&aligned_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccfcfdd1",
      "metadata": {
        "id": "ccfcfdd1"
      },
      "outputs": [],
      "source": [
        "def prepare_knn_data(df, useful_classes, removed_classes):\n",
        "    \"\"\"Prepare data for KNN classification.\"\"\"\n",
        "    # Step 2: Detect samples related to removed classes\n",
        "    df['needs_replacement'] = df[removed_classes].max(axis=1)  # 1 if any removed class is active\n",
        "\n",
        "    # Step 3: Create the physiological label\n",
        "    def get_physio_label(row):\n",
        "        for cond in useful_classes:\n",
        "            if row[cond] == 1:\n",
        "                return cond\n",
        "        return None\n",
        "\n",
        "    df['physio_label'] = df.apply(get_physio_label, axis=1)\n",
        "\n",
        "    # Step 4: Split into clean vs. to-replace\n",
        "    to_replace = df[(df['needs_replacement'] == 1) & (df['physio_label'].isnull())].copy()\n",
        "    clean_physio = df[(df['needs_replacement'] == 0) & (df['physio_label'].notnull())].copy()\n",
        "    behavior_features = ['IN_ALLEYS', 'REST', 'EAT', 'ACTIVITY_LEVEL']\n",
        "\n",
        "    # Only disease cases for training\n",
        "    disease_classes = ['mastitis', 'lameness', 'oestrus', 'calving', 'other_disease']\n",
        "    train_disease = clean_physio[clean_physio['physio_label'].isin(disease_classes)]\n",
        "\n",
        "    X_train = train_disease[behavior_features]\n",
        "    y_train = train_disease['physio_label']\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    return to_replace, clean_physio, X_train_scaled, y_train, scaler, behavior_features\n",
        "\n",
        "# Prepare data for KNN\n",
        "# to_replace, clean_physio, X_train_scaled, y_train, scaler, behavior_features = prepare_knn_data(df, useful_classes, removed_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a919ac97",
      "metadata": {
        "id": "a919ac97"
      },
      "source": [
        "# with KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db966c45",
      "metadata": {
        "id": "db966c45"
      },
      "outputs": [],
      "source": [
        "def apply_knn_and_save(to_replace, clean_physio, X_train_scaled, y_train, scaler, behavior_features, useful_classes, output_path='final2_cleaned_and_reassigned_dataset.csv'):\n",
        "    \"\"\"Apply KNN to reassign labels and save the final dataset.\"\"\"\n",
        "    # Train KNN\n",
        "    knn = KNeighborsClassifier(n_neighbors=5)\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Step 6: Predict missing labels\n",
        "    X_missing = scaler.transform(to_replace[behavior_features])\n",
        "    predicted_labels = knn.predict(X_missing)\n",
        "\n",
        "    # Assign the new labels\n",
        "    to_replace['physio_label'] = predicted_labels\n",
        "\n",
        "    # Step 6.1: Analyze reassignment\n",
        "    reassignment_summary = pd.Series(predicted_labels).value_counts().reset_index()\n",
        "    reassignment_summary.columns = ['Physiological_Class', 'Number_of_Reassigned_Samples']\n",
        "    print(reassignment_summary)\n",
        "\n",
        "    # Step 7: Merge back\n",
        "    for cond in useful_classes:\n",
        "        to_replace.loc[to_replace['physio_label'] == cond, cond] = 1\n",
        "\n",
        "    # Clean removed columns\n",
        "    df_final = pd.concat([clean_physio, to_replace], axis=0)\n",
        "    df_final = df_final.drop(columns=removed_classes + ['needs_replacement'])\n",
        "\n",
        "    # Optional: reorder if needed\n",
        "    df_final = df_final.sort_values(by=['cow', 'date', 'hour']).reset_index(drop=True)\n",
        "\n",
        "    # Step 8: Save the cleaned and reconstructed dataset\n",
        "    df_final.to_csv(output_path, index=False)\n",
        "\n",
        "    # Show sample\n",
        "    return df_final[['cow', 'date', 'hour', 'physio_label']].sample(10)\n",
        "\n",
        "# Apply KNN and save\n",
        "# sample = apply_knn_and_save(to_replace, clean_physio, X_train_scaled, y_train, scaler, behavior_features, useful_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73bb1f7c",
      "metadata": {
        "id": "73bb1f7c"
      },
      "source": [
        "# one hour shifting process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e3f162e",
      "metadata": {
        "id": "4e3f162e"
      },
      "outputs": [],
      "source": [
        "def one_hour_shift_process(df, window_size_hours=24, min_valid_hours=18, shift_hours=1):\n",
        "    \"\"\"Perform one-hour shifting process to create windows.\"\"\"\n",
        "    condition_columns = ['oestrus', 'calving', 'lameness', 'mastitis', 'other_disease']\n",
        "\n",
        "    # Adjust hour 24 to 00 and increment the date\n",
        "    df['adjusted_date'] = df['date']\n",
        "    df['adjusted_hour'] = df['hour']\n",
        "    df.loc[df['hour'] == 24, 'adjusted_date'] = pd.to_datetime(df.loc[df['hour'] == 24, 'date']) + timedelta(days=1)\n",
        "    df.loc[df['hour'] == 24, 'adjusted_hour'] = 0\n",
        "\n",
        "    # Ensure datetime format\n",
        "    df['adjusted_date'] = pd.to_datetime(df['adjusted_date'])\n",
        "\n",
        "    # Combine adjusted_date and adjusted_hour into a timestamp\n",
        "    df['timestamp'] = pd.to_datetime(df['adjusted_date'].dt.strftime('%Y-%m-%d') + ' ' + df['adjusted_hour'].astype(str) + ':00:00')\n",
        "    df = df.sort_values(['cow', 'timestamp'])\n",
        "\n",
        "    # Group by cow\n",
        "    grouped = df.groupby('cow')\n",
        "    shifted_windows = []\n",
        "\n",
        "    for cow_id, group in grouped:\n",
        "        timestamps = group['timestamp'].tolist()\n",
        "        group = group.set_index('timestamp')  # Index by timestamp for easy lookup\n",
        "\n",
        "        print(f\"\\nüêÑ Processing cow {cow_id} with {len(timestamps)} records...\")\n",
        "\n",
        "        for start_time in timestamps:\n",
        "            end_time = start_time + timedelta(hours=window_size_hours)\n",
        "            collected_hours = []\n",
        "            current_time = start_time\n",
        "            previous_date = current_time.date()\n",
        "\n",
        "            while current_time < end_time:\n",
        "                if current_time in group.index:\n",
        "                    current_date = current_time.date()\n",
        "\n",
        "                    # Stop if there's a day gap\n",
        "                    if (current_date - previous_date).days > 1:\n",
        "                        print(f\"üõë Stopping at {current_time} due to missing day.\")\n",
        "                        break\n",
        "\n",
        "                    collected_hours.append(group.loc[current_time]['ACTIVITY_LEVEL'])\n",
        "                    previous_date = current_date\n",
        "                    current_time += timedelta(hours=1)\n",
        "                else:\n",
        "                    # Hour is missing, skip it but advance time\n",
        "                    print(f\"‚ö†Ô∏è  Missing hour at {current_time}, skipping.\")\n",
        "                    current_date = current_time.date()\n",
        "\n",
        "                    if (current_date - previous_date).days > 0:\n",
        "                        print(f\"üõë Stopping at {current_time} due to day gap after missing hour.\")\n",
        "                        break\n",
        "\n",
        "                    previous_date = current_date\n",
        "                    current_time += timedelta(hours=1)\n",
        "\n",
        "            if len(collected_hours) >= min_valid_hours:\n",
        "                end_effective = start_time + timedelta(hours=len(collected_hours) - 1)\n",
        "\n",
        "                # Get condition values across the window\n",
        "                condition_window = group.loc[start_time:end_effective]\n",
        "                condition_counts = condition_window[condition_columns].sum()\n",
        "\n",
        "                # Prepare final label dictionary: all 0s initially\n",
        "                final_conditions = {col: 0 for col in condition_columns}\n",
        "                final_conditions['OK'] = 1\n",
        "\n",
        "                if (condition_counts > 0).any():\n",
        "                    most_frequent_condition = condition_counts.idxmax()\n",
        "                    final_conditions[most_frequent_condition] = 1\n",
        "                    final_conditions['OK'] = 0\n",
        "\n",
        "                shifted_windows.append({\n",
        "                    'cow': cow_id,\n",
        "                    'start_time': start_time,\n",
        "                    'end_time': end_effective,\n",
        "                    'duration_hours': len(collected_hours),\n",
        "                    'activity_window': collected_hours,\n",
        "                    **final_conditions\n",
        "                })\n",
        "\n",
        "                print(f\"‚úÖ Window for cow {cow_id} ‚Üí {most_frequent_condition if (condition_counts > 0).any() else 'healthy'}\")\n",
        "            else:\n",
        "                print(f\"‚ùå Discarded window for cow {cow_id} from {start_time}: only {len(collected_hours)} valid hours.\")\n",
        "\n",
        "    # Final DataFrame\n",
        "    shifted_df = pd.DataFrame(shifted_windows)\n",
        "\n",
        "    print(\"\\n‚úÖ DONE.\")\n",
        "    print(f\"Total valid windows collected: {len(shifted_df)}\")\n",
        "    display(shifted_df.head())\n",
        "\n",
        "    return shifted_df\n",
        "\n",
        "# Perform one-hour shift process\n",
        "# shifted_df = one_hour_shift_process(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8cd8485",
      "metadata": {
        "id": "b8cd8485"
      },
      "outputs": [],
      "source": [
        "def save_shifted_data(shifted_df, output_path='OneHourShift.csv'):\n",
        "    \"\"\"Save the shifted dataset to CSV.\"\"\"\n",
        "    shifted_df.to_csv(output_path, index=False)\n",
        "    print(f\"CSV file saved to {output_path}\")\n",
        "\n",
        "# Save shifted data\n",
        "# save_shifted_data(shifted_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
