{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, fft\n",
    "from datetime import timedelta\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "load-preprocess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath):\n",
    "    \"\"\"Load and preprocess the dataset.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(by=['cow', 'date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "health-durations",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_health_state_durations(df, health_state_column):\n",
    "    \"\"\"Calculate durations for specific health states.\"\"\"\n",
    "    durations = []\n",
    "\n",
    "    for cow_id, group in df.groupby('cow'):\n",
    "        group = group.sort_values('date').reset_index(drop=True)\n",
    "        current_state = False\n",
    "        start_date = None\n",
    "        prev_date = None\n",
    "\n",
    "        for i, row in group.iterrows():\n",
    "            if row[health_state_column] == 1:\n",
    "                if not current_state:\n",
    "                    current_state = True\n",
    "                    start_date = row['date']\n",
    "                elif prev_date is not None and (row['date'] - prev_date).days > 1:\n",
    "                    end_date = prev_date\n",
    "                    duration = (end_date - start_date).days + 1\n",
    "                    durations.append({\n",
    "                        'cow': cow_id,\n",
    "                        'health_state': health_state_column,\n",
    "                        'start_date': start_date,\n",
    "                        'end_date': end_date,\n",
    "                        'duration_days': duration\n",
    "                    })\n",
    "                    start_date = row['date']\n",
    "            else:\n",
    "                if current_state:\n",
    "                    end_date = prev_date if prev_date is not None else row['date']\n",
    "                    duration = (end_date - start_date).days + 1\n",
    "                    durations.append({\n",
    "                        'cow': cow_id,\n",
    "                        'health_state': health_state_column,\n",
    "                        'start_date': start_date,\n",
    "                        'end_date': end_date,\n",
    "                        'duration_days': duration\n",
    "                    })\n",
    "                    current_state = False\n",
    "                    start_date = None\n",
    "            prev_date = row['date']\n",
    "\n",
    "        if current_state:\n",
    "            end_date = prev_date\n",
    "            duration = (end_date - start_date).days + 1\n",
    "            durations.append({\n",
    "                'cow': cow_id,\n",
    "                'health_state': health_state_column,\n",
    "                'start_date': start_date,\n",
    "                'end_date': end_date,\n",
    "                'duration_days': duration\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "analyze-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_health_states(df, health_states):\n",
    "    \"\"\"Analyze and display health state durations.\"\"\"\n",
    "    state_durations = {}\n",
    "    durations_min_max = {}\n",
    "\n",
    "    for state in health_states:\n",
    "        durations_df = get_health_state_durations(df, state)\n",
    "        state_durations[state] = durations_df\n",
    "\n",
    "        if not durations_df.empty:\n",
    "            min_duration = durations_df['duration_days'].min()\n",
    "            max_duration = durations_df['duration_days'].max()\n",
    "            durations_min_max[state] = {'min_days': min_duration, 'max_days': max_duration}\n",
    "        else:\n",
    "            durations_min_max[state] = {'min_days': None, 'max_days': None}\n",
    "\n",
    "    for state, durations in durations_min_max.items():\n",
    "        min_days = durations['min_days']\n",
    "        max_days = durations['max_days']\n",
    "\n",
    "        if min_days is None or max_days is None:\n",
    "            print(f\"No data available for \\\"{state}\\\".\")\n",
    "        elif min_days == max_days:\n",
    "            print(f\"{state.capitalize()} lasts {min_days} day{'s' if min_days > 1 else ''}.\")\n",
    "        else:\n",
    "            print(f\"{state.capitalize()} lasts between {min_days} and {max_days} days.\")\n",
    "    \n",
    "    return state_durations, durations_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "label-align",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_and_align_data(df):\n",
    "    \"\"\"Label and align the dataset with event spreading rules.\"\"\"\n",
    "    non_event_cols = ['cow', 'date', 'hour', 'in_alleys', 'rest', 'eat', 'activity_level', 'ok']\n",
    "    event_cols = [col for col in df.columns if col not in non_event_cols]\n",
    "\n",
    "    daily = df.groupby(['cow', 'date'])[event_cols].max().reset_index()\n",
    "    daily['date'] = pd.to_datetime(daily['date'])\n",
    "\n",
    "    all_dates = pd.date_range(daily['date'].min() - timedelta(days=7), daily['date'].max() + timedelta(days=7))\n",
    "    cows = daily['cow'].unique()\n",
    "    full_daily = pd.MultiIndex.from_product([cows, all_dates], names=['cow', 'date']).to_frame(index=False)\n",
    "\n",
    "    full_daily = full_daily.merge(daily, on=['cow', 'date'], how='left')\n",
    "    full_daily[event_cols] = full_daily[event_cols].fillna(0)\n",
    "\n",
    "    full_daily['LABEL'] = 'control'\n",
    "    full_daily['OK'] = 1\n",
    "\n",
    "    spread_rules = {\n",
    "        'oestrus': {'before': 1, 'after': 1},\n",
    "        'calving': {'before': 2, 'after': 1},\n",
    "        'lameness': {'before': 2, 'after': 1},\n",
    "        'mastitis': {'before': 2, 'after': 1},\n",
    "        'acidosis': {'before': 2, 'after': 1},\n",
    "        'LPS': {'before': 2, 'after': 1},\n",
    "        'other_disease': {'before': 2, 'after': 1},\n",
    "        'accidents': {'before': 2, 'after': 1},\n",
    "        'disturbance': {'before': 0, 'after': 0},\n",
    "        'mixing': {'before': 0, 'after': 0},\n",
    "        'management_changes': {'before': 0, 'after': 0},\n",
    "    }\n",
    "\n",
    "    for cond in event_cols:\n",
    "        if cond not in spread_rules:\n",
    "            continue\n",
    "        sub = full_daily[full_daily[cond] == 1][['cow', 'date']].sort_values(['cow', 'date'])\n",
    "        for cow_id in sub['cow'].unique():\n",
    "            cow_days = sub[sub['cow'] == cow_id]['date'].sort_values()\n",
    "            episode = []\n",
    "            prev_day = None\n",
    "            for day in cow_days:\n",
    "                if prev_day is None or (day - prev_day).days > 1:\n",
    "                    if episode:\n",
    "                        min_day = min(episode)\n",
    "                        max_day = max(episode)\n",
    "                        spread = spread_rules[cond]\n",
    "                        spread_days = pd.date_range(min_day - timedelta(days=spread['before']), max_day + timedelta(days=spread['after']))\n",
    "                        mask = (full_daily['cow'] == cow_id) & (full_daily['date'].isin(spread_days))\n",
    "                        full_daily.loc[mask, cond] = 1\n",
    "                        full_daily.loc[mask & (full_daily['LABEL'] == 'control'), 'LABEL'] = cond\n",
    "                        full_daily.loc[mask, 'OK'] = 0\n",
    "                    episode = [day]\n",
    "                else:\n",
    "                    episode.append(day)\n",
    "                prev_day = day\n",
    "            if episode:\n",
    "                min_day = min(episode)\n",
    "                max_day = max(episode)\n",
    "                spread = spread_rules[cond]\n",
    "                spread_days = pd.date_range(min_day - timedelta(days=spread['before']), max_day + timedelta(days=spread['after']))\n",
    "                mask = (full_daily['cow'] == cow_id) & (full_daily['date'].isin(spread_days))\n",
    "                full_daily.loc[mask, cond] = 1\n",
    "                full_daily.loc[mask & (full_daily['LABEL'] == 'control'), 'LABEL'] = cond\n",
    "                full_daily.loc[mask, 'OK'] = 0\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.drop(columns=event_cols + ['OK'], errors='ignore')\n",
    "\n",
    "    final = df.merge(full_daily[['cow', 'date', 'LABEL'] + event_cols + ['OK']], on=['cow', 'date'], how='left')\n",
    "\n",
    "    for cond in event_cols:\n",
    "        final.loc[(final['LABEL'] == cond) & (final[cond] == 0), cond] = 1\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-reassign",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_reassign_data(df, useful_classes, removed_classes):\n",
    "    \"\"\"Clean data and reassign labels using KNN.\"\"\"\n",
    "    df['had_removed_class'] = df[removed_classes].max(axis=1)\n",
    "    df['has_useful_class'] = df[useful_classes].max(axis=1)\n",
    "    \n",
    "    rows_to_reassign = df[(df['had_removed_class'] == 1) & (df['has_useful_class'] == 0)]\n",
    "    total_rows = len(df)\n",
    "    total_to_reassign = len(rows_to_reassign)\n",
    "    proportion = total_to_reassign / total_rows * 100\n",
    "\n",
    "    print(f\"Total rows in dataset: {total_rows}\")\n",
    "    print(f\"Rows needing reassignment: {total_to_reassign}\")\n",
    "    print(f\"Proportion needing reassignment: {proportion:.2f}%\")\n",
    "\n",
    "    df['needs_replacement'] = df[removed_classes].max(axis=1)\n",
    "\n",
    "    def get_physio_label(row):\n",
    "        for cond in useful_classes:\n",
    "            if row[cond] == 1:\n",
    "                return cond\n",
    "        return None\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "\n",
    "    df['physio_label'] = df.apply(get_physio_label, axis=1)\n",
    "    to_replace = df[(df['needs_replacement'] == 1) & (df['physio_label'].isnull())].copy()\n",
    "    clean_physio = df[(df['needs_replacement'] == 0) & (df['physio_label'].notnull())].copy()\n",
    "\n",
    "    behavior_features = ['in_alleys', 'rest', 'eat', 'activity_level']\n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    disease_classes = ['mastitis', 'lameness', 'oestrus', 'other_disease','ok']\n",
    "\n",
    "    train_disease = clean_physio[clean_physio['physio_label'].isin(disease_classes)]\n",
    "    X_train = train_disease[behavior_features]\n",
    "    y_train = train_disease['physio_label']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "    X_missing = scaler.transform(to_replace[behavior_features])\n",
    "    predicted_labels = knn.predict(X_missing)\n",
    "    to_replace['physio_label'] = predicted_labels\n",
    "\n",
    "    reassignment_summary = pd.Series(predicted_labels).value_counts().reset_index()\n",
    "    reassignment_summary.columns = ['Physiological_Class', 'Number_of_Reassigned_Samples']\n",
    "    print(reassignment_summary)\n",
    "\n",
    "    for cond in useful_classes:\n",
    "        to_replace.loc[to_replace['physio_label'] == cond, cond] = 1\n",
    "\n",
    "    df_final = pd.concat([clean_physio, to_replace], axis=0)\n",
    "    df_final = df_final.drop(columns=removed_classes + ['needs_replacement'])\n",
    "    df_final = df_final.sort_values(by=['cow', 'date', 'hour']).reset_index(drop=True)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "shift-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hour_shifted_windows(df, window_size_hours=24, min_valid_hours=18, shift_hours=1):\n",
    "    \"\"\"Create one-hour shifted windows from the dataset.\"\"\"\n",
    "    condition_columns = ['oestrus', 'lameness', 'mastitis', 'other_disease','ok']\n",
    "    \n",
    "    df['adjusted_date'] = df['date']\n",
    "    df['adjusted_hour'] = df['hour']\n",
    "    df.loc[df['hour'] == 24, 'adjusted_date'] = pd.to_datetime(df.loc[df['hour'] == 24, 'date']) + timedelta(days=1)\n",
    "    df.loc[df['hour'] == 24, 'adjusted_hour'] = 0\n",
    "    \n",
    "    df['adjusted_date'] = pd.to_datetime(df['adjusted_date'])\n",
    "    df['timestamp'] = pd.to_datetime(df['adjusted_date'].dt.strftime('%Y-%m-%d') + ' ' + df['adjusted_hour'].astype(str) + ':00:00')\n",
    "    df = df.sort_values(['cow', 'timestamp'])\n",
    "    \n",
    "    grouped = df.groupby('cow')\n",
    "    shifted_windows = []\n",
    "    \n",
    "    for cow_id, group in grouped:\n",
    "        timestamps = group['timestamp'].tolist()\n",
    "        group = group.set_index('timestamp')\n",
    "        \n",
    "        for start_time in timestamps:\n",
    "            end_time = start_time + timedelta(hours=window_size_hours)\n",
    "            collected_hours = []\n",
    "            current_time = start_time\n",
    "            previous_date = current_time.date()\n",
    "            \n",
    "            while current_time < end_time:\n",
    "                if current_time in group.index:\n",
    "                    current_date = current_time.date()\n",
    "                    \n",
    "                    if (current_date - previous_date).days > 1:\n",
    "                        break\n",
    "                    \n",
    "                    collected_hours.append(group.loc[current_time]['activity_level'])\n",
    "                    previous_date = current_date\n",
    "                    current_time += timedelta(hours=1)\n",
    "                else:\n",
    "                    current_date = current_time.date()\n",
    "                    \n",
    "                    if (current_date - previous_date).days > 0:\n",
    "                        break\n",
    "                    \n",
    "                    previous_date = current_date\n",
    "                    current_time += timedelta(hours=1)\n",
    "            \n",
    "            if len(collected_hours) >= min_valid_hours:\n",
    "                end_effective = start_time + timedelta(hours=len(collected_hours) - 1)\n",
    "                condition_window = group.loc[start_time:end_effective]\n",
    "                condition_counts = condition_window[condition_columns].sum()\n",
    "                \n",
    "                final_conditions = {col: 0 for col in condition_columns}\n",
    "                \n",
    "                if (condition_counts > 0).any():\n",
    "                    most_frequent_condition = condition_counts.idxmax()\n",
    "                    final_conditions[most_frequent_condition] = 1\n",
    "                    final_conditions['ok'] = 0\n",
    "                else:\n",
    "                    final_conditions['ok'] = 1\n",
    "                \n",
    "                shifted_windows.append({\n",
    "                    'cow': cow_id,\n",
    "                    'start_time': start_time,\n",
    "                    'end_time': end_effective,\n",
    "                    'duration_hours': len(collected_hours),\n",
    "                    'activity_window': collected_hours,\n",
    "                    **final_conditions\n",
    "                })\n",
    "    \n",
    "    shifted_df = pd.DataFrame(shifted_windows)\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "process-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(input_path, output_path, health_states, useful_classes, removed_classes):\n",
    "    \"\"\"Process a complete dataset from input to output.\"\"\"\n",
    "    print(f\"\\nProcessing dataset: {input_path}\")\n",
    "    \n",
    "    # Step 1: Load and preprocess\n",
    "    df = load_and_preprocess_data(input_path)\n",
    "    \n",
    "    # Step 2: Analyze health states\n",
    "    print(\"\\nAnalyzing health states:\")\n",
    "    state_durations, durations_min_max = analyze_health_states(df, health_states)\n",
    "    \n",
    "    # Step 3: Label and align data\n",
    "    print(\"\\nLabeling and aligning data...\")\n",
    "    labeled_df = label_and_align_data(df)\n",
    "    \n",
    "    # Step 4: Clean and reassign data\n",
    "    print(\"\\nCleaning and reassigning data...\")\n",
    "    cleaned_df = clean_and_reassign_data(labeled_df, useful_classes, removed_classes)\n",
    "    \n",
    "    # Step 5: Create shifted windows\n",
    "    # print(\"\\nCreating one-hour shifted windows...\")\n",
    "    # shifted_df = create_one_hour_shifted_windows(cleaned_df)\n",
    "    \n",
    "    # Save results\n",
    "    cleaned_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\n✅ Processing complete. Results saved to {output_path}\")\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "main-execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: C:/Users/lamia/Desktop/datasets/dataset1_physiological.csv\n",
      "\n",
      "Analyzing health states:\n",
      "Oestrus lasts 1 day.\n",
      "Calving lasts 1 day.\n",
      "Lameness lasts 1 day.\n",
      "Mastitis lasts between 2 and 3 days.\n",
      "Ok lasts between 1 and 44 days.\n",
      "Other_disease lasts 1 day.\n",
      "No data available for \"accidents\".\n",
      "Disturbance lasts between 1 and 2 days.\n",
      "Mixing lasts between 1 and 2 days.\n",
      "No data available for \"management_changes\".\n",
      "\n",
      "Labeling and aligning data...\n",
      "\n",
      "Cleaning and reassigning data...\n",
      "Total rows: 106269\n",
      "Rows to reassign: 5546 (5.22%)\n",
      "Error processing C:/Users/lamia/Desktop/datasets/dataset1_physiological.csv: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "health_states = ['oestrus', 'calving', 'lameness', 'mastitis', 'ok' ,\n",
    "                'other_disease', 'accidents', 'disturbance', 'mixing', 'management_changes']\n",
    "\n",
    "useful_classes = ['mastitis', 'lameness', 'oestrus', 'calving', 'other_disease', 'ok']\n",
    "removed_classes = ['management_changes', 'mixing', 'disturbance', 'accidents']\n",
    "\n",
    "# Define datasets to process\n",
    "datasets = [\n",
    "      {\"input\": r\"C:/Users/lamia/Desktop/datasets/dataset1_physiological.csv\", \"output\": r\"C:/Users/lamia/Desktop/datasets/processed_dataset1.csv\"}\n",
    "    # {\"input\": \"C:\\Users\\lamia\\Desktop\\datasets\\dataset2_physiological.csv\", \"output\": \"processed_dataset2.csv\"},\n",
    "    # {\"input\": \"C:\\Users\\lamia\\Desktop\\datasets\\dataset3_physiological.csv\", \"output\": \"processed_dataset3.csv\"},\n",
    "    # {\"input\": \"C:\\Users\\lamia\\Desktop\\datasets\\dataset4_physiological.csv\", \"output\": \"processed_dataset4.csv\"}\n",
    "]\n",
    "\n",
    "# Process each dataset\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        process_dataset(\n",
    "            dataset[\"input\"],\n",
    "            dataset[\"output\"],\n",
    "            health_states,\n",
    "            useful_classes,\n",
    "            removed_classes\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dataset['input']}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b88c23ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: C:/Users/lamia/Desktop/datasets/dataset2_physiological.csv\n",
      "\n",
      "Analyzing health states:\n",
      "Oestrus lasts between 1 and 2 days.\n",
      "Lameness lasts 1 day.\n",
      "Mastitis lasts 1 day.\n",
      "Ok lasts between 1 and 6 days.\n",
      "Other_disease lasts 1 day.\n",
      "No data available for \"accidents\".\n",
      "Disturbance lasts between 1 and 4 days.\n",
      "No data available for \"mixing\".\n",
      "Management_changes lasts between 1 and 11 days.\n",
      "\n",
      "Labeling and aligning data...\n",
      "\n",
      "Cleaning and reassigning data...\n",
      "Total rows in dataset: 40247\n",
      "Rows needing reassignment: 15840\n",
      "Proportion needing reassignment: 39.36%\n",
      "Available columns: ['cow', 'date', 'hour', 'in_alleys', 'rest', 'eat', 'activity_level', 'ok', 'LABEL', 'oestrus', 'lameness', 'mastitis', 'other_disease', 'accidents', 'disturbance', 'mixing', 'management_changes', 'OK', 'had_removed_class', 'has_useful_class', 'needs_replacement']\n",
      "  Physiological_Class  Number_of_Reassigned_Samples\n",
      "0                  ok                         15819\n",
      "1            lameness                            16\n",
      "2             oestrus                             4\n",
      "3            mastitis                             1\n",
      "\n",
      "Creating one-hour shifted windows...\n",
      "\n",
      "✅ Processing complete. Results saved to C:/Users/lamia/Desktop/datasets/processed_dataset2.csv\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "health_states = ['oestrus',  'lameness', 'mastitis', 'ok' ,\n",
    "                'other_disease', 'accidents', 'disturbance', 'mixing', 'management_changes']\n",
    "\n",
    "useful_classes = ['mastitis', 'lameness', 'oestrus',  'other_disease', 'ok']\n",
    "removed_classes = ['management_changes', 'mixing', 'disturbance', 'accidents']\n",
    "\n",
    "# Define datasets to process\n",
    "datasets = [\n",
    "      {\"input\": r\"C:/Users/lamia/Desktop/datasets/dataset2_physiological.csv\", \"output\": r\"C:/Users/lamia/Desktop/datasets/processed_dataset2.csv\"}\n",
    "    # {\"input\": \"C:\\Users\\lamia\\Desktop\\datasets\\dataset2_physiological.csv\", \"output\": \"processed_dataset2.csv\"},\n",
    "    # {\"input\": \"C:\\Users\\lamia\\Desktop\\datasets\\dataset3_physiological.csv\", \"output\": \"processed_dataset3.csv\"},\n",
    "    # {\"input\": \"C:\\Users\\lamia\\Desktop\\datasets\\dataset4_physiological.csv\", \"output\": \"processed_dataset4.csv\"}\n",
    "]\n",
    "\n",
    "# Process each dataset\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        process_dataset(\n",
    "            dataset[\"input\"],\n",
    "            dataset[\"output\"],\n",
    "            health_states,\n",
    "            useful_classes,\n",
    "            removed_classes\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dataset['input']}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
