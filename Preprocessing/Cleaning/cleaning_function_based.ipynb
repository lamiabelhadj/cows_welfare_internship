{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2wQ6XTCpCFO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to dynamically identify health-related columns\n",
        "def identify_health_labels(df, exclude_cols=['cow', 'date', 'hour', 'IN_ALLEYS', 'REST', 'EAT', 'ACTIVITY_LEVEL']):\n",
        "    # Identify columns that are likely binary health indicators\n",
        "    potential_health_cols = [col for col in df.columns if col not in exclude_cols]\n",
        "    health_labels = [col for col in potential_health_cols \n",
        "                     if df[col].dropna().isin([0, 1]).all()]\n",
        "    return health_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_a09ySZpCFP"
      },
      "outputs": [],
      "source": [
        "def load_dataset(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tY0MSO3pCFY"
      },
      "source": [
        "### Check Completeness per Cow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ-BOty_pCFY"
      },
      "outputs": [],
      "source": [
        "def check_completeness_per_cow(df):\n",
        "    # Convert 'date' to datetime\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "    # Calculate expected date range\n",
        "    all_dates = pd.date_range(start=df['date'].min(), end=df['date'].max(), freq='D')\n",
        "\n",
        "    # Group by cow and count unique dates\n",
        "    cow_date_counts = df.groupby('cow')['date'].nunique()\n",
        "\n",
        "    # Compare against expected number of days\n",
        "    expected_days = len(all_dates)\n",
        "    missing_days_per_cow = expected_days - cow_date_counts\n",
        "\n",
        "    print(\"\\nMissing days per cow:\")\n",
        "    print(missing_days_per_cow[missing_days_per_cow > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84a6SGRhpCFY"
      },
      "source": [
        "### The number of hourly entries per cow per day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iNtQPNCpCFZ"
      },
      "outputs": [],
      "source": [
        "def count_hourly_entries(df):\n",
        "    hourly_counts = df.groupby(['cow', 'date']).size().reset_index(name='hourly_records')\n",
        "    print(hourly_counts)\n",
        "    return hourly_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpLihe3hpCFZ"
      },
      "source": [
        "### Filter for days with exactly 24 hours records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqRCgwxapCFZ"
      },
      "outputs": [],
      "source": [
        "def filter_full_days(df):\n",
        "    hourly_counts = df.groupby(['cow', 'date']).size().reset_index(name='hourly_records')\n",
        "    full_days = hourly_counts[hourly_counts['hourly_records'] == 24]\n",
        "    print(f\"\\nDays with full days of records: {len(full_days)}\")\n",
        "    return full_days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km4veqaHpCFa"
      },
      "source": [
        "### The number of full 24-hour days per cow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb8BPH96pCFa"
      },
      "outputs": [],
      "source": [
        "def count_full_days_per_cow(df):\n",
        "    hourly_counts = df.groupby(['cow', 'date']).size().reset_index(name='hourly_records')\n",
        "    full_days = hourly_counts[hourly_counts['hourly_records'] == 24]\n",
        "    full_days_per_cow = full_days.groupby('cow').size().reset_index(name='full_24h_days')\n",
        "    print(\"\\nFull 24h days per cow:\", full_days_per_cow)\n",
        "    return full_days_per_cow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXJc5zVppCFa"
      },
      "outputs": [],
      "source": [
        "def calculate_percentage_complete_days(df):\n",
        "    hourly_counts = df.groupby(['cow', 'date']).size().reset_index(name='hourly_records')\n",
        "    full_days = hourly_counts[hourly_counts['hourly_records'] == 24]\n",
        "    print(f\"Percentage of complete days: {len(full_days)/len(hourly_counts)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQwQTzNOpCFa"
      },
      "source": [
        "### Count how many 24h samples have less than 12 observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jgot85XvpCFa"
      },
      "outputs": [],
      "source": [
        "def count_less_than_12_obs(df):\n",
        "    hourly_counts = df.groupby(['cow', 'date']).size().reset_index(name='hourly_records')\n",
        "    less_than_12_obs = hourly_counts[hourly_counts['hourly_records'] < 12]\n",
        "    print(f\"Number of cow-day combinations with less than 12 hourly records: {len(less_than_12_obs)}\")\n",
        "    if len(less_than_12_obs) > 0:\n",
        "        print(less_than_12_obs)\n",
        "    return less_than_12_obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3GybLQDpCFb"
      },
      "source": [
        "# We will execute this code on the dataset that has 24h with less than 12 observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDDz-4v8pCFb"
      },
      "outputs": [],
      "source": [
        "def filter_less_than_12_obs(df):\n",
        "    hourly_counts = df.groupby(['cow', 'date']).size().reset_index(name='hourly_records')\n",
        "    less_than_12_obs = hourly_counts[hourly_counts['hourly_records'] < 12]\n",
        "    df_filtered = df.copy()\n",
        "    if len(less_than_12_obs) > 0:\n",
        "        # Filter for valid cow-date combinations (at least 12 hourly records)\n",
        "        valid_days = hourly_counts[hourly_counts['hourly_records'] >= 12]\n",
        "        # Merge back to original data to keep only valid records\n",
        "        df_filtered = pd.merge(df, valid_days[['cow', 'date']], on=['cow', 'date'], how='inner')\n",
        "        # df_filtered now excludes cow-date combos with <12 hours\n",
        "        print(df_filtered)\n",
        "    return df_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Perform cleaning by keeping only records with more that 18 samples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_by_observation_count(file_path, min_obs=18, output_path='filtered_dataset_more_than_18_obs.csv'):\n",
        "    df_cleaned = pd.read_csv(file_path)\n",
        "    df_cleaned['date'] = pd.to_datetime(df_cleaned['date'])\n",
        "\n",
        "    hourly_counts = df_cleaned.groupby(['cow', 'date']).size().reset_index(name='hour_count')\n",
        "\n",
        "    # Identify 24h records by observation count\n",
        "    records_more_than_18_obs = hourly_counts[hourly_counts['hour_count'] > min_obs]\n",
        "    records_12_to_18_obs = hourly_counts[(hourly_counts['hour_count'] >= 12) & (hourly_counts['hour_count'] <= min_obs)]\n",
        "    records_less_than_12_obs = hourly_counts[hourly_counts['hour_count'] < 12]\n",
        "\n",
        "    # Merge to filter full rows from original dataframe\n",
        "    df_more_than_18_obs = df_cleaned.merge(records_more_than_18_obs[['cow', 'date']], on=['cow', 'date'])\n",
        "    df_12_to_18_obs = df_cleaned.merge(records_12_to_18_obs[['cow', 'date']], on=['cow', 'date'])\n",
        "    df_less_than_12_obs = df_cleaned.merge(records_less_than_12_obs[['cow', 'date']], on=['cow', 'date'])\n",
        "\n",
        "    # Drop the records with less than 12 observations from the main dataset\n",
        "    df_filtered = df_cleaned[~df_cleaned.set_index(['cow', 'date']).index.isin(df_less_than_12_obs.set_index(['cow', 'date']).index)]\n",
        "\n",
        "    # Print dataset shapes\n",
        "    print(\"Original dataset shape:\", df_cleaned.shape)\n",
        "    print(f\"After filtering (<12 obs removed):\", df_filtered.shape)\n",
        "    print(f\"Deleted rows (<12 obs):\", df_less_than_12_obs.shape)\n",
        "    print(f\"Filtered dataset (>{min_obs} obs):\", df_more_than_18_obs.shape)\n",
        "    print(f\"Filtered dataset (12â€“{min_obs} obs):\", df_12_to_18_obs.shape)\n",
        "\n",
        "    # Save the dataset with more than 18 observations\n",
        "    df_more_than_18_obs.to_csv(output_path, index=False)\n",
        "    return df_more_than_18_obs, df_filtered, df_12_to_18_obs, df_less_than_12_obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Perform another cleaning by keeping only physiological classes**\n",
        "\n",
        "Retain: mastitis, lameness, oestrus, calving, other_disease, OK.\n",
        "\n",
        "Remove: management_changes, mixing, disturbance, accidents, LPS, acidosis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_by_physiological_classes(file_path, output_path='dataset3_aligned_cleaned_keep_physiological.csv', unwanted_classes=['management_changes', 'mixing', 'disturbance', 'accidents', 'lps', 'acidosis']):\n",
        "    # Step 0: Load the dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "    # Step 1: Define useful and unwanted classes\n",
        "    health_labels = identify_health_labels(df)\n",
        "    useful_classes = [col for col in health_labels if col not in unwanted_classes]\n",
        "\n",
        "    # Step 2: Keep only useful columns (non-health columns + useful health classes)\n",
        "    keep_cols = ['cow', 'date', 'hour', 'IN_ALLEYS', 'REST', 'EAT', 'ACTIVITY_LEVEL'] + useful_classes\n",
        "    keep_cols = [col for col in keep_cols if col in df.columns]  # Ensure columns exist\n",
        "    df_cleaned = df[keep_cols]\n",
        "\n",
        "    # Step 3: Save the cleaned dataset\n",
        "    df_cleaned.to_csv(output_path, index=False)\n",
        "\n",
        "    # Optional: Show a sample\n",
        "    print(df_cleaned.head())\n",
        "    return df_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage for multiple datasets\n",
        "datasets = ['dataset1.csv', 'dataset2.csv', 'dataset3.csv', 'dataset4.csv']  # Replace with your actual dataset paths\n",
        "for file_path in datasets:\n",
        "    print(f\"\\nAnalyzing {file_path}\")\n",
        "    df = load_dataset(file_path)\n",
        "    print(\"\\nCheck Completeness per Cow:\")\n",
        "    check_completeness_per_cow(df)\n",
        "    print(\"\\nHourly Entries per Cow per Day:\")\n",
        "    count_hourly_entries(df)\n",
        "    print(\"\\nDays with Exactly 24 Hours Records:\")\n",
        "    filter_full_days(df)\n",
        "    print(\"\\nFull 24-Hour Days per Cow:\")\n",
        "    count_full_days_per_cow(df)\n",
        "    print(\"\\nPercentage of Complete Days:\")\n",
        "    calculate_percentage_complete_days(df)\n",
        "    print(\"\\nCow-Day Combinations with Less than 12 Hourly Records:\")\n",
        "    count_less_than_12_obs(df)\n",
        "    print(\"\\nFiltered Dataset (Excluding <12 obs):\")\n",
        "    df_filtered = filter_less_than_12_obs(df)\n",
        "    print(\"\\nCleaning by Observation Count (>18 obs):\")\n",
        "    output_path_obs = f\"filtered_{file_path.split('.')[0]}_more_than_18_obs.csv\"\n",
        "    df_more_than_18, df_filtered_obs, df_12_to_18, df_less_than_12 = clean_by_observation_count(file_path, output_path=output_path_obs)\n",
        "    print(\"\\nCleaning by Physiological Classes:\")\n",
        "    output_path_phys = f\"cleaned_{file_path.split('.')[0]}_physiological.csv\"\n",
        "    df_phys_cleaned = clean_by_physiological_classes(file_path, output_path=output_path_phys)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}